import streamlit as st
import numpy as np
import pandas as pd

st.sidebar.title("DataJob :chart_with_downwards_trend:")
st.sidebar.header("Menu")
pages =["Exploration","Preprocessing","Visualisation","Mod√©lisation", "Conclusion", "Ouvertures"]
page = st.sidebar.radio("",options = pages)
'\n\n'
st.sidebar.info(
    "Projet Datajob - Promotion Bootcamp mars 2023"
    "\n\n"
    "Participants:"
    "\n\n"
    "David DUBOIS"
    "\n\n"
    "Pauline WOLFF"
    "\n\n"
    "Sophie LAUSSEL\n "
    )

if page == pages[0]:  
    st.title(':orange[Exploration] :mag_right:')
    st.header("Description")
    st.markdown('''<div style="text-align: justify;">
                L‚Äôobjectif de ce projet est de comprendre √† l‚Äôaide des donn√©es les diff√©rents profils techniques qui se sont cr√©√©s dans l‚Äôindustrie de la Data. 
                Plus exactement, nous m√®nerons une analyse pouss√©e des t√¢ches effectu√©es ainsi que des outils utilis√©s pour chaque poste afin d‚Äô√©tablir des 
                ensembles de comp√©tences et outils correspondant √† chaque poste du monde de la Data.
                Ce projet s‚Äôint√®gre parfaitement dans notre projet professionnel. Il nous permet d‚Äôanalyser, √† l‚Äôaide de ce jeu de donn√©es, 
                les diff√©rents m√©tiers de la data √† travers les logiciels utilis√©s, les √©tudes des diff√©rents profils etc. 
                </div>''', unsafe_allow_html=True)
    '\n'

    st.header("Objectifs")
    st.markdown(
                """
                Les principaux objectifs qui ressortent √† travers ce sondages sont :
                - analyser les profils des utilisateurs de Kaggle au regard de leur m√©tier
                - √©laborer un mod√®le permettant d‚Äôidentifier le m√©tier data le plus adapt√©, en fonction des comp√©tences des personnes souhaitant int√©grer le domaine de la data.
                """
                )    
    '\n'

    st.header("Cadre")
    st.markdown('''<div style="text-align: justify;">
                Le jeu de donn√©es sur lequel nous allons travailler provient d‚Äôun sondage cr√©√© et lanc√© en 2020 sur 171 pays. Il √©tait destin√© aux personnes inscrites sur le site Kaggle (plateforme web interactive qui propose des comp√©titions d'apprentissage automatique en science des donn√©es). Au total, 20 000 personnes ont √©t√© sond√©es. L‚Äô√©tude est essentiellement centr√©e sur le Machine Learning.
                Nous proc√©dons √† une premi√®re analyse visuelle sur le jeu de donn√©es (√† l‚Äôaide de la m√©thode info de pandas). 
                </div>''', unsafe_allow_html=True)
     
    st.markdown('''<div style="text-align: justify;">
                Ainsi le jeu de donn√©es se d√©compose de la mani√®re suivante :
                </div>''', unsafe_allow_html=True)
    st.markdown("- 355 colonnes,")
    st.markdown("- l‚Äôint√©gralit√© des donn√©es sont de type objet donc qualitatives, il y a 20 037 entr√©es.")
    st.markdown(''' <style> [data-testid="stMarkdownContainer"] ul{list-style-position: inside;}</style>    ''', unsafe_allow_html=True)

    st.markdown('''<div style="text-align: justify;">
                D‚Äôun point de vue technique, toutes les donn√©es √©tant de type qualitatif, nous aurons un important travail d‚Äôencodage √† faire pour pouvoir traiter la donn√©e. 
                </div>''', unsafe_allow_html=True) 
    '\n'
    
    st.header("Variable cible :dart:")
    st.markdown('''<div style="text-align: justify;">
                La variable cible de notre projet correspond aux m√©tiers de la data dans le jeu de donn√©es, cette variable se nomme ‚Äútitre‚Äô, que nous appellerons M√©tier, terme plus explicite. Nous √©tudierons les 4 m√©tiers : 
                Data Scientest
                Data Analyst
                Machine Learning Engineer
                Data Engineer 
                </div>''', unsafe_allow_html=True) 
    '\n'
    
    st.header("Remarques sur le dataset")
    col1, col2 = st.columns(2)
    with col1:
        st.subheader(':red[Difficult√©s]')
        st.write(
            '''
            - les questions √† choix multiples g√©n√®rent une colonne distincte dans le dataset : **355** colonnes pour **39** questions
            - une grande quantit√© d‚Äôintervalles et de bornes : cat√©gorie ‚Äúobjet‚Äù par d√©faut
            - certaines questions r√©serv√©es aux √©tudiants et aux employ√©s
            - des questions ne sont d√©bloqu√©es qu'en fonction de la r√©ponse √† une question en amont -> beaucoup de ‚Äú**NaN**‚Äù g√©n√©r√©s artificiellement
            - nous identifions des ‚Äú**None**‚Äù et ‚Äú**other**‚Äù qui seront √† analyser par la suite
            - doublons √† analyser et corriger
            '''
        )

    with col2:
        st.subheader(':green[Points positifs]')
        st.write(
            '''
            - aucune zone de texte libre 
            - ensemble des r√©ponses normalis√©
            - pas de diff√©rences entre majuscules ou minuscules par exemple
            - pas de nettoyage √† faire sur la police ou la casse
            ''')

if page == pages[1]: 
    st.title(':orange[Preprocessing] :tornado:')    
    st.write('''
             - Suppression de la premi√®re ligne avec le nom des questions \n\n
             - Suppression de la colonne ***duration*** \n\n
             - Suppression des colonnes ***partie B*** qui correspondaient aux r√©ponses des non-salari√©s \n\n
             - Regroupement des colonnes √† r√©ponses multiples afin d'√©liminer un maximum de ***NaN*** et pour nous permettre d'utiliser ses donn√©es dans nos graphiques \n\n
             - Suppression des colonnes √† r√©ponses multiples \n\n
             - Renommer les colonnes \n\n
             - Suppression des doublons \n\n
             - Suppression des ***m√©tiers*** qui ne font pas partie de la data \n\n
             - Remplacement des ***NaN*** par le mode \n\n
             ''')

if page == pages[2]: 
    st.title(':orange[Visualisation] :eyes:')
    #st.header("Titre")
    #st.write("write")
    #st.markdown("Markdown")
    tab1, tab2, tab3, tab4, tab5, tab6= st.tabs(["üìà Pie chart", "üìà Chart 2","üìà Chart3","üìà Chart4","üìà Chart5","üìà Heatmap"])
    tab1.subheader("R√©partition des m√©tiers de la Data")
    tab1.image("Piechart.png")
    tab1.info("Nous constatons une forte concentration des Data Scientist (47%).") 
    #tab2.subheader("A tab with the data")

    tab2.subheader("La Data dans le monde")
    tab2.image("pays1.png")
    tab2.image("pays.png")
    tab2.info("Forte concentration des profils en Inde et aux Etats-Unis")

    tab3.subheader("Age")
    tab3.image("Age.png")
    tab3.info("Concentration des 22-29 ans")

    tab4.subheader("R√©mun√©ration")
    tab4.image("Remuneration.png")
    tab4.info("Quelques valeurs extr√®mes")

    tab5.subheader("Langage de programmation")
    tab5.image("language.png")
    tab5.image("langage par metier.png")
    tab5.info("Les deux langages les plus utilis√©s en programmation sont  Python et  SQL.")

    tab6.subheader("Heatmap")
    tab6.image("heatmap.png")
    tab6.image("zoom heatmap.png")
    tab6.info("La heatmap compl√®te contenant un volume important de donn√©es, nous avons d√©cid√© de faire une analyse cibl√©e sur les questions sur le machine learning et le cloud.")

if page == pages[3]: 
    st.title(':orange[Mod√©lisation ]	:sparkles:')
    options = ['','SVM', 'KNN','Arbre de d√©cision', 'RandomForest', 'Regression logistique']
    st.header("S√©lection d'un mod√®le")
    selected = st.selectbox('Quel mod√®le choississez vous?',
                            options = options)
    st.write('Vous avez choisi:', selected)

    if selected == '':
        st.write("")
    elif selected == 'SVM':
        st.image('SVM.png')
        st.info(":red[Accuracy √† **0,56** apr√®s optimisation et mauvaise d√©tection de la classe 3.] \n\n Bien que nous ayons am√©lior√© l'accuracy, nous avons perdu en qualit√© sur la d√©tection de la classe 3. \n\n :point_right: **Mod√®le non s√©lectionn√©**")
        code = st.checkbox('Voir code')
        if code :
            st.code(
                '''
                from sklearn.multiclass import OneVsRestClassifier
                ovr2=OneVsRestClassifier(SVC())
                ovr2.fit(X_train,y_train)
                ''')    
    elif selected == 'KNN' :
        st.image('KNN.png')
        st.info(":red[Accuracy √† **0,45** apr√®s optimisation et mauvaise d√©tection de la classe 3.] \n\n Nous n'avons pas am√©lior√© ce mod√®le. \n\n :point_right: **Mod√®le non s√©lectionn√©**")   
        code = st.checkbox('Voir code')
        if code :
            st.code(
                '''
                knn = neighbors.KNeighborsClassifier()
                parametres = {'n_neighbors': range(2,50)}
                grid_knn = model_selection.GridSearchCV(estimator=knn, param_grid=parametres)
                grid_knn.fit(X_train, y_train)
                grid_knn.best_params_
                grid_knn.score(X_test, y_test)
                ''')
    elif selected == 'Arbre de d√©cision' :
        st.image('ADD.png')
        st.info(":red[Accuracy √† **0,44** apr√®s r√©√©quilibrage.] \n\n Le r√©√©quilibrage des classes a permis de d√©tecter la 3√®me classe, mais la d√©tection des classes 0 et 1 a baiss√©. \n\n :point_right: **Mod√®le non s√©lectionn√©**")   
        code = st.checkbox('Voir code')
        if code :
            st.code(
                '''
                param_grid = {'criterion': ['gini', 'entropy'], 'max_depth': np.arange(3, 10)}
                clf_gs = GridSearchCV(model, param_grid) 
                clf_gs.fit(X_train, y_train)
                ''')
    elif selected == 'RandomForest' :
        st.image('RF.png')
        st.info(":red[Accuracy √† **0,57** avant optimisation, et 0,55 apr√®s optimisation] \n\n L'am√©lioration du mod√®le n'a pas permis d'am√©liorer le score et d√©tecte tr√®s mal la classe 3, le seul avantage est qu'il √©vite un overfitting. \n\n :point_right: **Mod√®le s√©lectionn√© !**")    
        code = st.checkbox('Voir code')
        if code :
            st.code(
                '''
                param_grid = {'criterion': ['gini', 'entropy'], 'max_depth': np.arange(3, 20)}
                clf_gs = GridSearchCV(rf, param_grid) 
                clf_gs.fit(X_train, y_train)
                ''')
    else :
        st.image('RL.png')
        st.info(":red[Accuracy √† 0,56 avant optimisation, **0,57** apr√®s optimisation et mauvaise d√©tection de la classe 3] \n\n Pas d'am√©lioration de mod√®le. \n\n :point_right: **Mod√®le non s√©lectionn√©**")    
        code = st.checkbox('Voir code')
        if code :
            st.code(
                '''
                parameters = {'penalty' : ['l1','l2'], 
                            'C': np.logspace(-3,3,7),
                            'solver'  : ['newton-cg', 'lbfgs', 'liblinear']}
                clf_gs = GridSearchCV(reglog,
                                    param_grid = parameters,
                                    scoring='accuracy',
                                    cv=10) 
                clf_gs.fit(X_train, y_train)
                ''')
    code = st.checkbox('Voir le comparatif')
    if code :
            st.subheader("Coefficient :red[avant] optimisation")
            df = pd.read_csv("RecapML_1.csv", sep=';')
            st.dataframe(df.style.highlight_max(axis=0))

            st.subheader("Coefficient :red[apr√®s] optimisation")
            df = pd.read_csv("RecapML_2.csv", sep=';')
            st.dataframe(df.style.highlight_max(axis=0))

if page == pages[4]: 

    st.title(':orange[Conclusion] :ballot_box_with_check:')
    #st.header("Titre")
    #st.write("write")
    #st.markdown("Markdown")
    st.write('''
            - il est primordial de **prendre le temps de bien comprendre** l‚Äôobjectif du projet ; ici, un cas de classification, puisque cet objectif va sous-tendre l‚Äôensemble de notre travail (par exemple, la r√©duction de dimension de donn√©es)\n
            - l‚Äôexploration, l‚Äôanalyse et le pr√©-processing des donn√©es sont des t√¢ches **complexes**, tr√®s **chronophages** mais **indispensables** avant de construire des mod√®les de Machine Learning (ML). 
            - l‚Äôutilisation des mod√®les de ML standards comme le SVM, le Random Forest‚Ä¶ fut **simple** ; il nous a suffi d‚Äôappliquer les commandes des cours de Datascientest en consid√©rant ces mod√®les comme des utilitaires ou des boites noires
            - les **taux de pr√©diction** obtenus par les multiples mod√®les de ML tournaient autour de seulement 50%. Ceux-ci ne sont **pas satisfaisants**, nous avons alors optimis√© ces mod√®les avec des techniques genre Bagging, Boosting‚Ä¶ mais aussi en faisant varier les valeurs de leurs hyperparam√®tres via la m√©thode GridSearchCV
            - ces deux voies ne nous ont pas permis de d√©passer un taux de 56% ; le **frein** principal √† nos tentatives d‚Äôoptimisations fut notre **niveau technique sur le ML** et la difficult√© √† appr√©hender le r√¥le de chaque **hyperparam√®tre** de chaque mod√®le de ML
            - le ML n‚Äôest **pas une solution miracle** ; si le probl√®me √† traiter est trop complexe et les donn√©es pas assez nombreuses ou de qualit√©, notre mod√®le ne pourra pas atteindre un taux de pr√©cision de 70 ou 80%
            ''')
    
if page == pages[5]:
    st.title(':orange[Ouvertures] 	:globe_with_meridians:')
    st.subheader('Ouverture 1 : prise en compte de tous les m√©tiers de la data')

    st.write('''
            Pour notre projet, nous avons filtr√© les donn√©es du sondage de Kaggle pour ne retenir que quatre m√©tiers : 
            ***Data Analyst, Data Scientist, Data Engineer, Machine Learning Engineer***
            \n\n
            En r√©alit√©, le monde de la data est 
            bien plus complexe et ses m√©tiers 
            plus nombreux. 
            \n\n
            En se basant sur ces sites web, nous
            avons identifi√© vingt m√©tiers :
            - https://www.data-bird.co/metiers-data#data-steward 
            - https://www.kdnuggets.com/2021/10/guide-14-different-data-science-jobs.html

            Une fois notre mod√®le de ML optimis√© sur les quatre m√©tiers de base, nous pourrons tester celui-ci sur l‚Äôensemble des vingt. L‚Äôobjectif sera √† nouveau de trouver le poste le plus pr√©cis√©ment adapt√© √† chaque informaticien en reconversion. 
            - Architecte Big Data
            - Business analyst
            - Business intelligence (BI) developer
            - Chief Data Officer
            - Computer & information research scientist Data analyst
            - Dataarchitect
            - Data engineer
            - Data manager
            - Data miner
            - Data modeler
            - Data Protection Officer Data scientist
            - Data steward
            - Database administrator 
            - Machine Learning Engineer 
            - Marketing scientist 
            - Quantitative analyst 
            - Software engineer 
            - Statistician
            ''')
    
    st.subheader('Ouverture 2 : √©largissement du mod√®le aux non informaticiens')
    st.write('''
            Un autre axe d‚Äô√©volution sera d‚Äôadapter notre mod√®le aux personnes n‚Äôayant aucun background informatique et d√©sireuses de travailler dans le monde de la data (par go√ªt ou opportunit√© √©conomique). 
            Dans ce cas, les donn√©es en entr√©e seront de nature totalement diff√©rente de celles du sondage de Kaggle. 
		
            Nous pourrons utiliser des attributs non li√©s √† l‚Äôinformatique pour construire ce nouveau mod√®le de ML :
            - langues parl√©es
            - type d‚Äô√©tude (scientifique, litt√©raire, √©conomique‚Ä¶)
            - app√©tence pour les langages informatiques ou le management
            - salaire souhait√©
            - autres
            √Ä partir de ces attributs, notre mod√®le devra proposer un poste dans la data o√π la personne aura le plus de chance de r√©ussir sa reconversion.
            ''')
